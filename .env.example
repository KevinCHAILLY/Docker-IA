# Configuration Ollama
# Adresse d'écoute du serveur Ollama (0.0.0.0 pour écouter sur toutes les interfaces)
OLLAMA_HOST=0.0.0.0:11434

# Répertoire des modèles
OLLAMA_MODELS=/root/.ollama/models

# Durée pendant laquelle les modèles restent chargés en mémoire
OLLAMA_KEEP_ALIVE=5m

# Liste d'origines autorisées séparées par des virgules (pour CORS)
OLLAMA_ORIGINS=

# Mode debug (true pour activer, false pour désactiver)
OLLAMA_DEBUG=false

# Nombre maximum de requêtes parallèles (0 pour illimité)
OLLAMA_NUM_PARALLEL=0

# Nombre maximum de requêtes en file d'attente
OLLAMA_MAX_QUEUE=512

# Délai maximum pour le chargement d'un modèle
OLLAMA_LOAD_TIMEOUT=5m

# Ne pas élaguer les blobs de modèle au démarrage (true pour activer)
OLLAMA_NOPRUNE=false

# Type de quantification pour le cache K/V (par défaut: f16)
OLLAMA_KV_CACHE_TYPE=f16

# Optimise le cache de prompts pour les scénarios multi-utilisateurs
OLLAMA_MULTIUSER_CACHE=false

# Longueur de contexte à utiliser sauf indication contraire
OLLAMA_CONTEXT_LENGTH=2048

# Configuration Open WebUI
# Activer l'authentification (true/false)
WEBUI_AUTH=true

# Nom de l'interface Web
WEBUI_NAME=Ollama WebUI

# URL de l'interface Web
WEBUI_URL=http://localhost:3000

# Clé secrète pour l'authentification (à changer pour la production)
WEBUI_SECRET_KEY=changeme 